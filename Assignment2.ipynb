{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Assignment 2: Naive Bayes and KNN classifier\n",
    "\n",
    "In this assignment you'll implement the Naive Bayes and KNN classifier to classify patients as either having or not having diabetic retinopathy. For this task we'll be using the same Diabetic Retinopathy data set which was used in the previous assignment on decision trees. The implementation details are up to you but, generally it is a good idea to divide your code up into helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log\n",
    "from math import floor\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataBind:\n",
    "    def __init__(self, minimum, maximum, probYes, probNo):\n",
    "        self.minimum = minimum\n",
    "        self.maximum = maximum\n",
    "        self.probYes = probYes\n",
    "        self.probNo = probNo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPoint:\n",
    "    def __str__(self):\n",
    "        return \"< \" + str(self.label) + \": \" + str(self.features) + \" >\"\n",
    "    def __init__(self, label, features):\n",
    "        self.label = label # the classification label of this data point\n",
    "        self.features = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    data = []\n",
    "    file_data = pd.read_csv(filename, skipinitialspace=True, header=None)\n",
    "    for i in range(0,len(file_data)):\n",
    "        data.append(DataPoint(file_data.iloc[i,19],file_data.iloc[i,0:19]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Naive Bayes Classifier\n",
    "\n",
    "Naive Bayes (NB) classifier is a simple probabilistic classifier that is based on applying the Bayes' theorem and assumes a strong (naive) independence between features. The Diabetic Retinopath data set contains both categorical and continuous features. Dealing with categorical features has been already been discussed in detail in class. Continuous attributes, on the other hand, are more interesting to handle. Most commonly, this is done by assuming normal probability distribution over the feature values or by binning the attribute values in a fixed number of bins. In this assignment you'll be implementing the binning approach. For each continuous attribute, you'll construct 3 equal sized bins. For example, feature 5 ranges from `[1 - 120]` the 3 bins that you'll construct will be `[1 - 40]`, `[41 - 80]`, `[81 - 120]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix of probability\n",
    "def get_mat_prob(data):\n",
    "    mat=[]\n",
    "    size_data = len(data)\n",
    "    yes_label = sum(x.label==1 for x in data)\n",
    "    no_label = sum(x.label!=1 for x in data)\n",
    "    for i in range(0,len(data[0].features)):\n",
    "        data.sort(key = lambda x: x.features[i])\n",
    "        minim = data[0].features[i]\n",
    "        maxim = data[size_data - 1].features[i]\n",
    "        sizebind = floor((maxim-minim)/3)\n",
    "        max_bind_one = minim + sizebind\n",
    "        max_bind_two = max_bind_one + sizebind + 1\n",
    "        bind_one_yes = sum(x.features[i] >= minim and x.features[i] <= max_bind_one and x.label == 1 for x in data)\n",
    "        bind_one_no = sum(x.features[i] >= minim and x.features[i] <= max_bind_one and x.label != 1 for x in data)\n",
    "        bind_two_yes = sum(x.features[i] >= max_bind_one+1 and x.features[i] <= max_bind_two and x.label == 1 for x in data)\n",
    "        bind_two_no = sum(x.features[i] >= max_bind_one+1 and x.features[i] <= max_bind_two and x.label != 1 for x in data)\n",
    "        bind_three_yes = sum(x.features[i] >= max_bind_two+1 and x.features[i] <= maxim and x.label == 1 for x in data)\n",
    "        bind_three_no = sum(x.features[i] >= max_bind_two+1 and x.features[i] <= maxim and x.label != 1 for x in data)\n",
    "        rowCol = []\n",
    "        # Ask to add 1 numerator and 1 to denominator (both label values (yes and no), also on final data)\n",
    "        if bind_one_yes == 0 or bind_one_no == 0:\n",
    "            rowCol.append(DataBind(minim,max_bind_one,(bind_one_yes+1)/(yes_label+1),(bind_one_no+1)/(no_label+1)))\n",
    "        else:\n",
    "            rowCol.append(DataBind(minim,max_bind_one,bind_one_yes/yes_label,bind_one_no/no_label))\n",
    "        if bind_two_yes == 0 or bind_two_no == 0:\n",
    "            rowCol.append(DataBind(max_bind_one+1,max_bind_two,(bind_two_yes+1)/(yes_label+1),(bind_two_no+1)/(no_label+1)))       \n",
    "        else:\n",
    "            rowCol.append(DataBind(max_bind_one+1,max_bind_two,bind_two_yes/yes_label,bind_two_no/no_label))\n",
    "        if bind_three_yes == 0 or bind_three_no == 0:\n",
    "            rowCol.append(DataBind(max_bind_two+1,maxim,(bind_three_yes+1)/(yes_label+1),(bind_three_no+1)/(no_label+1)))\n",
    "        else:\n",
    "            rowCol.append(DataBind(max_bind_two+1,maxim,bind_three_yes/yes_label,bind_three_no/no_label))\n",
    "        mat.append(rowCol)\n",
    "    return yes_label,no_label,np.transpose(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prob(mat,yes_prob,no_prob,data):\n",
    "    bind = 3\n",
    "    j = 0\n",
    "    yes_prob_data = 1\n",
    "    no_prob_data = 1\n",
    "    sizeData = yes_prob + no_prob\n",
    "    for i in range(0,len(data.features)):\n",
    "        while j < bind :\n",
    "            if data.features[i] <= mat[j][i].maximum and data.features[i] >= mat[j][i].minimum:\n",
    "                yes_prob_data = yes_prob_data * mat[j][i].probYes\n",
    "                no_prob_data = no_prob_data * mat[j][i].probNo\n",
    "                break\n",
    "            j = j + 1\n",
    "        j = 0\n",
    "    yes_prob_data = yes_prob_data * (yes_prob/sizeData)\n",
    "    no_prob_data = no_prob_data * (no_prob/sizeData)\n",
    "    if yes_prob_data > no_prob_data:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, fold):\n",
    "    sizeStep = floor(len(data)/fold)\n",
    "    finalStep = sizeStep\n",
    "    i = 0\n",
    "    j = 0\n",
    "    folds = []\n",
    "    while i < fold:\n",
    "        data_fold = []\n",
    "        while j < finalStep:\n",
    "            data_fold.append(data[j])\n",
    "            j = j + 1\n",
    "        if i == fold-2:\n",
    "            finalStep = len(data)\n",
    "        else:\n",
    "            finalStep = finalStep + sizeStep\n",
    "        folds.append(data_fold)\n",
    "        i = i + 1\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accurracy_bayes(data):\n",
    "    fold = 5\n",
    "    i = 0\n",
    "    j = 0\n",
    "    sumIncorrect = 0\n",
    "    errorAverage = 0\n",
    "    \n",
    "    # making folds\n",
    "    array_fold = np.array_split(data,fold)\n",
    "    while i < fold:\n",
    "        train_set = array_fold[i+1:fold]+array_fold[0:i] #1,2,3,4 - 2,3,4,0\n",
    "        train_set_single = [x for lst in train_set for x in lst]\n",
    "        test_set = array_fold[i] #0 - 1\n",
    "        yes_prob, no_prob, m = get_mat_prob(train_set_single)\n",
    "        while j < len(test_set):\n",
    "            if data[j].label != make_prob(m,yes_prob,no_prob,data[j]):\n",
    "                sumIncorrect = sumIncorrect + 1\n",
    "            j = j + 1\n",
    "        errorAverage = errorAverage + sumIncorrect/len(test_set)\n",
    "        sumIncorrect = 0\n",
    "        j = 0\n",
    "        i = i + 1\n",
    "    return (1 - (errorAverage/fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.77112742330133\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "d = get_data(\"messidor_features.txt\")\n",
    "print(get_accurracy_bayes(d)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 2: K Nearest Neighbor (KNN) Classifier\n",
    "\n",
    "The KNN classifier consists of two stages:-\n",
    "- In the training stage, the classifier takes the training data and simply memorizes it\n",
    "- In the test stage, the classifier compares the test data with the training data and simply returns the maximum occuring label of the k nearest data points.\n",
    "\n",
    "The distance calculation method is central to the algorithm, typically Euclidean distance is used but other distance metrics like Manhattan distance can also be used. In this assignment you'll be implementing the classifier using the Euclidean distance metric. It is important to note that, Euclidean distance is very sensitive to the scaling of different attributes hence, before you can build your classifier you have to normalize the values of each feature in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm_data(filename):\n",
    "    data = []\n",
    "    file_data = pd.read_csv(filename, skipinitialspace=True, header=None)\n",
    "    # Normalize data\n",
    "    for i in range(0,len(file_data.columns)):\n",
    "        minimum = min(file_data.iloc[:,i])\n",
    "        maximum = max(file_data.iloc[:,i])\n",
    "        for j in range(0,len(file_data)):\n",
    "            file_data.iloc[j,i] = (file_data.iloc[j,i] - minimum)/(maximum - minimum)\n",
    "    # List of data points\n",
    "    for i in range(0,200):\n",
    "        data.append(DataPoint(file_data.iloc[i,19],file_data.iloc[i,0:19]))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_distance(dataX, dataY):\n",
    "    distance = 0\n",
    "    for i in range(0,len(dataX.features)):\n",
    "        distance = distance + pow(dataX.features[i]-dataY.features[i],2)\n",
    "    return pow(distance,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(train_set, dataPoint,k):\n",
    "    if sum([x.label for x in sorted(train_set, key = lambda y: euclidian_distance(y, dataPoint))][:k]) > k/2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(array_fold,fold):\n",
    "    i = 0\n",
    "    super_train_set = []\n",
    "    test_set = []\n",
    "    while i < fold:\n",
    "        train_set = array_fold[i+1:fold]+array_fold[0:i] #1,2,3,4 - 2,3,4,0\n",
    "        super_train_set.append([x for lst in train_set for x in lst])\n",
    "        test_set.append(array_fold[i])\n",
    "        i = i + 1\n",
    "    return super_train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_best_k(data,topK):\n",
    "    fold = 5\n",
    "    i = 0\n",
    "    j = 0\n",
    "    x = 0\n",
    "    sumIncorrect = 0\n",
    "    errorK = 0\n",
    "    \n",
    "    # making folds\n",
    "    array_fold = np.array_split(data,fold)\n",
    "    # making k list\n",
    "    kList = np.arange(1,topK,2)\n",
    "    kError = []\n",
    "    super_train_set, test_set = get_train_test(array_fold,fold)\n",
    "    while x < len(kList):\n",
    "        k = kList[x]\n",
    "        while i < fold:\n",
    "            while j < len(test_set[i]):\n",
    "                if test_set[i][j].label != knn(super_train_set[i],test_set[i][j],k):\n",
    "                    sumIncorrect = sumIncorrect + 1\n",
    "                j = j + 1\n",
    "            errorK = errorK + sumIncorrect/len(test_set[i])\n",
    "            sumIncorrect = 0\n",
    "            j = 0\n",
    "            i = i + 1\n",
    "        kError.append(errorK/fold)\n",
    "        errorK = 0\n",
    "        i = 0\n",
    "        x = x + 1\n",
    "    return kList, kError, kList[np.argmin(kError)]\n",
    "\n",
    "kList,kError,k=get_best_k(d,10)\n",
    "plt.scatter(kList,kError)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accurracy_bayes(data, k, fold):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    sumIncorrect = 0\n",
    "    errorK = 0\n",
    "    \n",
    "    # making folds\n",
    "    array_fold = np.array_split(data,fold)\n",
    "\n",
    "    super_train_set, test_set = get_train_test(array_fold,fold)\n",
    "    while i < fold:\n",
    "        while j < len(test_set[i]):\n",
    "            if test_set[i][j].label != knn(super_train_set[i],test_set[i][j],k):\n",
    "                sumIncorrect = sumIncorrect + 1\n",
    "            j = j + 1\n",
    "        errorK = errorK + sumIncorrect/len(test_set[i])\n",
    "        sumIncorrect = 0\n",
    "        j = 0\n",
    "        i = i + 1\n",
    "    return (1 - (errorK/fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.5\n"
     ]
    }
   ],
   "source": [
    "d = get_norm_data(\"messidor_features.txt\")\n",
    "kList,kError,k=get_best_k(d,10)\n",
    "print(get_accurracy_bayes(d,k,5)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
